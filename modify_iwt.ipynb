{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOQLx6y4x68GVvdABF5UW8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manas003884/repo2/blob/master/modify_iwt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5xM-oLeMJoz",
        "outputId": "0ed2fd08-69bf-4de7-f78a-97ae91b0269f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 75.19 dB\n",
            "MSE: 0.00\n",
            "Extracted Message: \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pywt\n",
        "from PIL import Image\n",
        "from skimage.metrics import peak_signal_noise_ratio, mean_squared_error\n",
        "from skimage.transform import resize\n",
        "\n",
        "def iwt_steganography(ci, sm, sk):\n",
        "    # Perform a single-level Haar wavelet decomposition\n",
        "    coeffs = pywt.dwt2(ci, 'haar')\n",
        "    ll, (hl, lh, hh) = coeffs\n",
        "\n",
        "    # Convert the HH, LH, and HL coefficient matrices into vectors\n",
        "    hh_vec = hh.flatten()\n",
        "    lh_vec = lh.flatten()\n",
        "    hl_vec = hl.flatten()\n",
        "\n",
        "    # Combine sm and sk into a single string\n",
        "    message_key = sm + sk\n",
        "\n",
        "    # Initialize the categories as lists of lists\n",
        "    categories = [[] for _ in range(7)]\n",
        "\n",
        "    # Assign each coefficient to a category\n",
        "    for i in range(len(hh_vec)):\n",
        "        # Cast the result of np.ceil to an integer\n",
        "        category_index = int(np.ceil(hh_vec[i] / 255.0))\n",
        "        categories[category_index].append(i)\n",
        "    for i in range(len(lh_vec)):\n",
        "        # Cast the result of np.ceil to an integer\n",
        "        category_index = int(np.ceil(lh_vec[i] / 255.0))\n",
        "        categories[category_index].append(i)\n",
        "    for i in range(len(hl_vec)):\n",
        "        # Cast the result of np.ceil to an integer\n",
        "        category_index = int(np.ceil(hl_vec[i] / 255.0))\n",
        "        categories[category_index].append(i)\n",
        "\n",
        "    # Embed the secret message bits\n",
        "    for i in range(7):\n",
        "        for j in categories[i]:\n",
        "            if message_key:\n",
        "                # Get the next bit from the combined message and key\n",
        "                next_bit = int(message_key[0])\n",
        "                hh_vec[j] = int(hh_vec[j])  # Convert to integer\n",
        "                hh_vec[j] = min(max(int(hh_vec[j]) & 254, 0), 255) | next_bit  # Embed the bit into the coefficient\n",
        "                message_key = message_key[1:]\n",
        "\n",
        "    # Reshape the HH, LH, and HL coefficient vectors back into matrices\n",
        "    hh = hh_vec.reshape(hh.shape)\n",
        "    lh = lh_vec.reshape(lh.shape)\n",
        "    hl = hl_vec.reshape(hl.shape)\n",
        "\n",
        "    # Perform the inverse Haar wavelet transform\n",
        "    stego_image = pywt.idwt2((ll, (hl, lh, hh)), 'haar')\n",
        "\n",
        "    return stego_image\n",
        "\n",
        "\n",
        "\n",
        "def extract_message_from_stego_image(stego_image, secret_key):\n",
        "    # Perform a single-level Haar wavelet decomposition on the stego image\n",
        "    coeffs = pywt.dwt2(stego_image, 'haar')\n",
        "    ll, (hl, lh, hh) = coeffs\n",
        "\n",
        "    # Convert the HH, LH, and HL coefficient matrices into vectors\n",
        "    hh_vec = hh.flatten()\n",
        "    lh_vec = lh.flatten()\n",
        "    hl_vec = hl.flatten()\n",
        "\n",
        "    # Initialize variables to store the extracted message, its binary representation, and its length\n",
        "    extracted_message = \"\"\n",
        "    binary_message = \"\"\n",
        "    message_length = 0\n",
        "\n",
        "    # Extract the message using the provided secret key\n",
        "    for i in range(len(hh_vec)):\n",
        "        if message_length < len(secret_key):\n",
        "            if secret_key[message_length] == '1':\n",
        "                binary_message += str(int(hh_vec[i]))\n",
        "            message_length += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    for i in range(len(lh_vec)):\n",
        "        if message_length < len(secret_key):\n",
        "            if secret_key[message_length] == '1':\n",
        "                binary_message += str(int(lh_vec[i]))\n",
        "            message_length += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    for i in range(len(hl_vec)):\n",
        "        if message_length < len(secret_key):\n",
        "            if secret_key[message_length] == '1':\n",
        "                binary_message += str(int(hl_vec[i]))\n",
        "            message_length += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Ensure the binary message length is a multiple of 8 (byte alignment)\n",
        "    padding = 8 - (len(binary_message) % 8)\n",
        "    if padding < 8:\n",
        "        binary_message = '0' * padding + binary_message\n",
        "\n",
        "    # Convert the binary message to a string\n",
        "    extracted_message = ''.join([chr(int(binary_message[i:i + 8], 2)) for i in range(0, len(binary_message), 8)])\n",
        "\n",
        "    return extracted_message\n",
        "\n",
        "def main():\n",
        "    # Input file paths\n",
        "    cover_image_path = \"/content/earth.png\"\n",
        "    secret_message_txt = \"/content/secret_message.txt\"\n",
        "    secret_key = \"rand45\"\n",
        "\n",
        "    # Load the cover image from file\n",
        "    cover_image = np.array(Image.open(cover_image_path))\n",
        "\n",
        "    # Load the secret message from a .txt file\n",
        "    with open(secret_message_txt, 'r') as file:\n",
        "        secret_message = file.read()\n",
        "\n",
        "    # Convert the secret message and secret key to binary format\n",
        "    secret_message_binary = ''.join(format(ord(char), '08b') for char in secret_message)\n",
        "    secret_key_binary = ''.join(format(ord(char), '08b') for char in secret_key)\n",
        "\n",
        "    # Perform image steganography\n",
        "    stego_image = iwt_steganography(cover_image, secret_message_binary, secret_key_binary)\n",
        "\n",
        "    # Ensure stego_image and cover_image have the same dimensions\n",
        "    if stego_image.shape != cover_image.shape:\n",
        "        stego_image = resize(stego_image, cover_image.shape, mode='reflect', anti_aliasing=True)\n",
        "\n",
        "    # Convert the stego image to uint8 format\n",
        "    stego_image_uint8 = np.uint8(stego_image)\n",
        "\n",
        "    # Save the stego image to a file\n",
        "    stego_image_path = \"stego_image.png\"\n",
        "    stego_image_pillow = Image.fromarray(stego_image_uint8)\n",
        "    stego_image_pillow.save(stego_image_path)\n",
        "\n",
        "    # Calculate PSNR and MSE\n",
        "    psnr_value = peak_signal_noise_ratio(cover_image, stego_image_uint8)\n",
        "    mse_value = mean_squared_error(cover_image, stego_image_uint8)\n",
        "\n",
        "    print(f\"PSNR: {psnr_value:.2f} dB\")\n",
        "    print(f\"MSE: {mse_value:.2f}\")\n",
        "\n",
        "    # Extract the hidden message from the stego image\n",
        "    extracted_message = extract_message_from_stego_image(stego_image_uint8, secret_key)\n",
        "\n",
        "    print(f\"Extracted Message: {extracted_message}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "def haar_wavelet_transform(gray_image):\n",
        "    \"\"\"\n",
        "    Applies the Haar wavelet transform to a grayscale image.\n",
        "    Args:\n",
        "        gray_image (numpy.ndarray): The grayscale image to transform.\n",
        "    Returns:\n",
        "        numpy.ndarray: The Haar wavelet coefficients of the image.\n",
        "    \"\"\"\n",
        "    # Initialize the Haar wavelet coefficients image\n",
        "    haar_image = np.zeros_like(gray_image)\n",
        "    # Iterate over the image in 2x2 blocks\n",
        "    for i in range(0, gray_image.shape[0], 2):\n",
        "        for j in range(0, gray_image.shape[1], 2):\n",
        "            # Calculate the average and difference values\n",
        "            avg = (gray_image[i, j] + gray_image[i+1, j] + gray_image[i, j+1] + gray_image[i+1, j+1]) / 4\n",
        "            diff = (gray_image[i, j] - gray_image[i+1, j] - gray_image[i, j+1] + gray_image[i+1, j+1]) / 4\n",
        "            # The average value is the low-pass filtered value\n",
        "            haar_image[i, j] = avg\n",
        "            # The difference value is the high-pass filtered value\n",
        "            haar_image[i+1, j] = diff\n",
        "            haar_image[i, j+1] = diff\n",
        "            haar_image[i+1, j+1] = -diff\n",
        "    # Return the Haar wavelet coefficients\n",
        "    return haar_image\n",
        "def inverse_haar_wavelet_transform(haar_image):\n",
        "    \"\"\"\n",
        "    Applies the inverse Haar wavelet transform to a grayscale image.\n",
        "    Args:\n",
        "        haar_image (numpy.ndarray): The Haar wavelet coefficients of the image.\n",
        "    Returns:\n",
        "        numpy.ndarray: The grayscale image.\n",
        "    \"\"\"\n",
        "    # Initialize the grayscale image\n",
        "    gray_image = np.zeros_like(haar_image)\n",
        "    # Iterate over the image in 2x2 blocks\n",
        "    for i in range(0, gray_image.shape[0], 2):\n",
        "        for j in range(0, gray_image.shape[1], 2):\n",
        "            # Calculate the average and difference values\n",
        "            avg = haar_image[i, j]\n",
        "            diff = haar_image[i+1, j]\n",
        "            # The average value is the low-pass filtered value\n",
        "            gray_image[i, j] = avg\n",
        "            # The difference value is the high-pass filtered value\n",
        "            gray_image[i+1, j] = avg - diff\n",
        "            gray_image[i, j+1] = avg - diff\n",
        "            gray_image[i+1, j+1] = avg + diff\n",
        "    # Return the grayscale image\n",
        "    return gray_image\n",
        "# Read the image\n",
        "image = cv2.imread('/content/earth.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "# Apply the Haar wavelet transform\n",
        "haar_image = haar_wavelet_transform(image)\n",
        "# Apply the inverse Haar wavelet transform\n",
        "gray_image = inverse_haar_wavelet_transform(haar_image)\n",
        "# Convert the image back to color\n",
        "color_image = cv2.cvtColor(gray_image, cv2.COLOR_GRAY2BGR)\n",
        "# Display the original and transformed images\n",
        "cv2.imshow('Original Image', image)\n",
        "cv2.imshow('Haar Wavelet Transform', haar_image)\n",
        "cv2.imshow('Inverse Haar Wavelet Transform', gray_image)\n",
        "cv2.imshow('Color Image', color_image)\n",
        "# Wait for a key press\n",
        "cv2.waitKey(0)\n",
        "# Close the windows\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "HN-jzq6xRv8N",
        "outputId": "77d6a514-f8c9-47a4-fb2b-8cda3404022a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-683900349973>:18: RuntimeWarning: overflow encountered in ubyte_scalars\n",
            "  diff = (gray_image[i, j] - gray_image[i+1, j] - gray_image[i, j+1] + gray_image[i+1, j+1]) / 4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-683900349973>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/earth.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Apply the Haar wavelet transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mhaar_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhaar_wavelet_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;31m# Apply the inverse Haar wavelet transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mgray_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minverse_haar_wavelet_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhaar_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-683900349973>\u001b[0m in \u001b[0;36mhaar_wavelet_transform\u001b[0;34m(gray_image)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# Calculate the average and difference values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgray_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgray_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgray_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgray_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgray_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgray_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgray_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgray_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# The average value is the low-pass filtered value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 225 is out of bounds for axis 1 with size 225"
          ]
        }
      ]
    }
  ]
}